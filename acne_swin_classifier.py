# -*- coding: utf-8 -*-
"""ACNE_Swin_Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QfE3wByERYm4qa-4AIuyRND1YggQXPCl
"""

'''
파이토치 쿠다설정
https://blog.naver.com/me_a_me/223570004477

python = 3.11.11
torch = 2.6.0
cuda = 12.4
cudnn = 9.1.0.70

pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
'''

from google.colab import drive
drive.mount('/content/drive')

import os

path = '/content/drive/My Drive/AI Project I'

# 데이터 파일 경로 설정
file_path = os.path.join(path)  # 예시 파일 경로

import os
import io
import timm
import cv2

from PIL import Image
from tqdm.auto import tqdm  # Progress bars
from PIL import ImageFile

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from collections import Counter


import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torchvision.datasets import ImageFolder

import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.utils.data import Subset, random_split

import albumentations as A
from albumentations.pytorch import ToTensorV2

import random
import torch
import numpy as np # 혹시 numpy를 사용하신다면 함께 시드를 고정해야 합니다.
import os

# 모든 시드(seed)를 설정하는 함수
def set_all_seeds(seed):
    random.seed(seed) # Python의 기본 random 모듈 시드 고정
    np.random.seed(seed) # NumPy 시드 고정 (사용하지 않으시면 생략 가능)
    torch.manual_seed(seed) # PyTorch CPU 연산 시드 고정
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed) # PyTorch 모든 GPU 연산 시드 고정
        # cuDNN의 비결정적 동작 방지: 핵심!
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False # 보통 deterministic과 함께 False로 설정
    # Python hash seed 고정 (딕셔너리, 해시 테이블 등에 영향을 줄 수 있습니다)
    os.environ['PYTHONHASHSEED'] = str(seed)

# 시드 설정 함수 호출
set_all_seeds(42)

# 이후 기존 코드 계속...
ImageFile.LOAD_TRUNCATED_IMAGES = True

import os

dataset_base_path = path
dataset_path_train = os.path.join(dataset_base_path, 'train')
dataset_path_valid = os.path.join(dataset_base_path, 'valid')
dataset_path_test = os.path.join(dataset_base_path, 'test')

csv_path_train = os.path.join(dataset_base_path, 'train/_classes.csv')
csv_path_valid = os.path.join(dataset_base_path, 'valid/_classes.csv')
csv_path_test = os.path.join(dataset_base_path, 'test/_classes.csv')

# 경로에서 이미지 파일 목록 가져오기
image_files_train = [f for f in os.listdir(dataset_path_train) if f.endswith(('.jpg', '.png'))]
image_files_valid = [f for f in os.listdir(dataset_path_valid) if f.endswith(('.jpg', '.png'))]
image_files_test = [f for f in os.listdir(dataset_path_test) if f.endswith(('.jpg', '.png'))]

print(f"train 이미지 파일 수: {len(image_files_train)}")
print(f"valid 이미지 파일 수: {len(image_files_valid)}")
print(f"test 이미지 파일 수: {len(image_files_test)}")

# 목록 합치기
image_files = image_files_train + image_files_valid + image_files_test

print(f"총 이미지 파일 수: {len(image_files)}")

# 이후 코드는 image_files를 사용하여 진행
# ...

#Dataset transformations are specified here

IMG_SIZE = 224  # Swin Transformer input size

IMG_SIZE = 224  # Swin Transformer input size

train_transform = A.Compose([
    A.Resize(IMG_SIZE, IMG_SIZE), # 크기변경
    A.HorizontalFlip(p=0.5), # 좌우 뒤집기
    # A.RandomBrightnessContrast(p=0.2), # 밝기와 대비 변경
    # Change the normalization parameters to ImageNet mean and std
    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), # 정규화
    ToTensorV2(),
])

test_transform = A.Compose([
    A.Resize(IMG_SIZE, IMG_SIZE),
    # Change the normalization parameters to ImageNet mean and std
    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
    ToTensorV2(),
])

class CustomDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.annotations = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform
        # 클래스 이름 목록을 정의합니다. CSV 파일에 맞게 수정하세요.
        self.classes = ['Pimples', 'blackhead', 'conglobata', 'crystanlline', 'cystic', 'folliculitis', 'keloid', 'milium', 'papular', 'purulent'] # Replace with your actual class names

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        img_name = os.path.join(self.root_dir, self.annotations.iloc[idx, 0]) # Adjust column index for image file name
        image = Image.open(img_name).convert('RGB')
        image = np.array(image)

        # 멀티 라벨 추출 및 처리
        # CSV 파일 구조에 따라 이 부분을 수정해야 합니다.
        # 예: 라벨이 여러 컬럼에 걸쳐 있다면 해당 컬럼들을 선택합니다.
        # Convert label columns to float before creating the tensor
        labels_data = self.annotations.iloc[idx, 1:].values.astype(np.float32)
        labels = torch.tensor(labels_data, dtype=torch.float32)

        if self.transform:
            image = self.transform(image=image)["image"]

        return image, labels

train_dataset = CustomDataset(csv_file=csv_path_train, root_dir=dataset_path_train, transform=train_transform)
valid_dataset = CustomDataset(csv_file=csv_path_valid, root_dir=dataset_path_valid, transform=train_transform)
test_dataset = CustomDataset(csv_file=csv_path_test, root_dir=dataset_path_test, transform=train_transform)

print(len(train_dataset))
print(len(valid_dataset))
print(len(test_dataset))

# 각 데이터셋에서 몇 개의 샘플을 확인합니다.
num_samples_to_check = 5

print("Checking train_dataset samples:")
for i in range(min(num_samples_to_check, len(train_dataset))):
    image, labels = train_dataset[i]
    print(f"Sample {i}: Image shape - {image.shape}, Labels - {labels}")

print("\nChecking valid_dataset samples:")
for i in range(min(num_samples_to_check, len(valid_dataset))):
    image, labels = valid_dataset[i]
    print(f"Sample {i}: Image shape - {image.shape}, Labels - {labels}")

print("\nChecking test_dataset samples:")
for i in range(min(num_samples_to_check, len(test_dataset))):
    image, labels = test_dataset[i]
    print(f"Sample {i}: Image shape - {image.shape}, Labels - {labels}")

"""# 언더샘플링 알고리즘 코드"""

# # 언더샘플링 알고리즘 코드
# import os
# import pandas as pd
# import random

# # --- 일관된 결과를 위해 랜덤 시드 설정 ---
# random.seed(42)

# import shutil
# from PIL import Image, ImageFile
# import torch
# import torch.nn as nn
# import torch.optim as optim
# from torch.utils.data import Dataset, DataLoader
# from torchvision import transforms
# import timm
# from tqdm import tqdm

# # --- 일관된 결과를 위한 랜덤 시드 설정 ---
# random.seed(42)
# torch.manual_seed(42)
# if torch.cuda.is_available():
#     torch.cuda.manual_seed_all(42)
# # --- 랜덤 시드 설정 끝 ---

# # 이미지 메모리 제한 해제
# Image.MAX_IMAGE_PIXELS = None
# ImageFile.LOAD_TRUNCATED_IMAGES = True

# # 경로 정의
# path = '/content/drive/My Drive/AI Project I'
# original_train_csv_path = os.path.join(path, 'train', '_classes.csv')
# undersampled_train_dir = os.path.join(path, 'train_undersampled')
# undersampled_train_csv_path = os.path.join(undersampled_train_dir, '_classes.csv')
# original_valid_csv_path = os.path.join(path, 'valid', '_classes.csv')
# original_test_csv_path = os.path.join(path, 'test', '_classes.csv')
# original_train_image_dir = os.path.join(path, 'train')
# original_valid_image_dir = os.path.join(path, 'valid')
# original_test_image_dir = os.path.join(path, 'test')

# # 언더샘플링된 데이터를 저장할 디렉토리 생성
# os.makedirs(undersampled_train_dir, exist_ok=True)

# # CSV 파일 로드 및 결합
# try:
#     df_train_orig = pd.read_csv(original_train_csv_path)
#     # 컬럼 이름에서 앞뒤 공백 제거 (KeyError 해결)
#     df_train_orig.columns = df_train_orig.columns.str.strip()
#     df_valid_orig = pd.read_csv(original_valid_csv_path)
#     df_valid_orig.columns = df_valid_orig.columns.str.strip()
#     df_test_orig = pd.read_csv(original_test_csv_path)
#     df_test_orig.columns = df_test_orig.columns.str.strip()

#     df_all_combined = pd.concat([df_train_orig, df_valid_orig, df_test_orig], ignore_index=True)
# except FileNotFoundError as e:
#     print(f"오류: CSV 파일을 찾을 수 없습니다. 경로를 확인해주세요. - {e}")
#     exit()

# # 모든 라벨 컬럼 식별
# all_labels = [col for col in df_all_combined.columns if col != 'filename']
# target_count_for_majority = 2500
# threshold_for_minority = 1000

# # 클래스별 개수 계산 및 소수/다수 클래스 분류
# global_class_counts = {label: df_all_combined[label].sum() for label in all_labels}
# minority_labels = {label: count for label, count in global_class_counts.items() if count <= threshold_for_minority}
# sorted_majority_labels_items = sorted({label: count for label, count in global_class_counts.items() if count > threshold_for_minority}.items(), key=lambda item: item[1], reverse=True)

# # 소수 클래스에 해당하는 파일명 보호
# protected_filenames_set = set()
# for _, row in df_train_orig.iterrows():
#     if any(row[m_label] == 1 for m_label in minority_labels):
#         protected_filenames_set.add(row['filename'])

# # 언더샘플링을 위해 제거할 이미지 식별
# images_to_remove_from_train = set()
# df_train_temp = df_train_orig.copy()

# for majority_label, _ in sorted_majority_labels_items:
#     current_count = df_train_temp[df_train_temp[majority_label] == 1].shape[0]
#     if current_count <= target_count_for_majority:
#         continue

#     num_to_remove = current_count - target_count_for_majority

#     candidates = df_train_temp[(df_train_temp[majority_label] == 1) & (~df_train_temp['filename'].isin(protected_filenames_set))]['filename'].tolist()
#     selected_for_removal = random.sample(candidates, num_to_remove) if len(candidates) >= num_to_remove else candidates
#     images_to_remove_from_train.update(selected_for_removal)
#     df_train_temp = df_train_orig[~df_train_orig['filename'].isin(images_to_remove_from_train)].copy()

# # 언더샘플링된 데이터프레임 생성 및 CSV 저장
# df_train_undersampled = df_train_orig[~df_train_orig['filename'].isin(images_to_remove_from_train)].copy()
# df_train_undersampled.to_csv(undersampled_train_csv_path, index=False)

# print("언더샘플링 완료.")
# print(f"원본 train 데이터셋 행 수: {df_train_orig.shape[0]} -> 언더샘플링 후 train 데이터셋 행 수: {df_train_undersampled.shape[0]}")

# # --- 언더샘플링된 이미지 파일들을 새 디렉토리로 복사 ---
# print("\n언더샘플링된 이미지 파일들을 새 디렉토리로 복사 중입니다...")

# copied_count = 0
# for filename in df_train_undersampled['filename']:
#     src_path = os.path.join(original_train_image_dir, filename)
#     dst_path = os.path.join(undersampled_train_dir, filename)
#     try:
#         if os.path.exists(src_path):
#             shutil.copy(src_path, dst_path)
#             copied_count += 1
#         else:
#             print(f"경고: 원본 이미지 '{src_path}'를 찾을 수 없습니다. 복사하지 않습니다.")
#     except Exception as e:
#         print(f"오류: '{src_path}'를 '{dst_path}'로 복사하는 중 오류 발생 - {e}")

# print(f"총 {copied_count}개의 이미지가 '{undersampled_train_dir}'로 복사되었습니다.")
# print("--- 이미지 파일 복사 완료 ---\n")

import matplotlib.pyplot as plt

# 언더샘플링 전 클래스 분포
#orig_counts = df_train_orig[all_labels].sum().sort_values(ascending=False)
# 언더샘플링 후 클래스 분포
#undersampled_counts = df_train_undersampled[all_labels].sum().sort_values(ascending=False)

# 시각화
#plt.figure(figsize=(14, 6))
#plt.subplot(1, 2, 1)
#orig_counts.plot(kind='bar', title='Original Class Distribution')

#plt.subplot(1, 2, 2)
#undersampled_counts.plot(kind='bar', title='Undersampled Class Distribution')
#plt.tight_layout()
#plt.show()

#dataset_path_train_us = os.path.join(dataset_base_path, 'train_undersampled')
#csv_path_train_us = os.path.join(dataset_base_path, 'train_undersampled/_classes.csv')
#image_files_train = [f for f in os.listdir(dataset_path_train_us) if f.endswith(('.jpg', '.png'))]

#train_dataset_us = CustomDataset(csv_file=csv_path_train_us, root_dir=dataset_path_train_us, transform=train_transform)
#valid_dataset = CustomDataset(csv_file=csv_path_valid, root_dir=dataset_path_valid, transform=train_transform)
#test_dataset = CustomDataset(csv_file=csv_path_test, root_dir=dataset_path_test, transform=train_transform)

#print(len(train_dataset_us))
#print(len(valid_dataset))
#print(len(test_dataset))

#num_samples_to_check = 5

#print("Checking train_dataset samples:")
#for i in range(min(num_samples_to_check, len(train_dataset_us))):
    #image, labels = train_dataset_us[i]
    #print(f"Sample {i}: Image shape - {image.shape}, Labels - {labels}")

"""모델 학습 데이터 경로
언더샘플링된 학습 데이터와 라벨 정보는 아래 경로에서 불러와 모델 학습에 활용하시면 됩니다.

데이터셋 폴더 경로 (이미지 파일이 있는 폴더):
/content/drive/My Drive/AI Project I/train_undersampled

CSV 파일 경로 (라벨 정보가 있는 파일):
/content/drive/My Drive/AI Project I/train_undersampled/_classes.csv
"""

#이미지 메모리 제한 해제
Image.MAX_IMAGE_PIXELS = None

class SwinClassifier(nn.Module):
    def __init__(self, num_classes=10):
        super(SwinClassifier, self).__init__()
        self.model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=num_classes)

    def forward(self, x):
        return self.model(x)

# cuda check
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

import random

ImageFile.LOAD_TRUNCATED_IMAGES = True  # Allow loading truncated images

random.seed(42)
torch.manual_seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(42)

# Set DataLoader parameters; using num_workers=0 for TPU stability
BATCH_SIZE = 32
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
val_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

print(f"train_dataset_us size: {len(train_dataset)}")
print(f"steps per epoch: {len(train_loader)}")

# Training hyperparameters
EPOCHS = 25
PATIENCE = 5
num_classes = 10

train_accuracies = []
val_accuracies = []

# Define your model, loss, optimizer, and scheduler
model = SwinClassifier(num_classes=10).to(device)
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.AdamW(model.parameters(), lr=0.0002, weight_decay=1e-4)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-5)

# Checkpoint file path
checkpoint_file = "checkpoint_acne.pth"
# checkpoint_file = "/content/gdrive/MyDrive/best_swin_model.pth"
# Initialize or resume training variables
start_epoch = 0
if os.path.exists(checkpoint_file):
    print("Checkpoint found. Resuming training from checkpoint...")
    # Load checkpoint to CPU first, then move state to TPU
    checkpoint = torch.load(checkpoint_file, map_location=torch.device("cpu"))
    model.load_state_dict(checkpoint['model_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
    start_epoch = checkpoint['epoch'] + 1
    best_val_acc = checkpoint.get('best_val_acc', 0.0)
    epochs_no_improve = checkpoint['epochs_no_improve']
    train_losses = checkpoint.get('train_losses', [])
    val_losses = checkpoint.get('val_losses', [])
    train_accuracies = checkpoint.get('train_accuracies', [])
    val_accuracies = checkpoint.get('val_accuracies', [])
    # Move the model to the TPU device
    model.to(device)
else:
    best_val_acc = 0.0
    epochs_no_improve = 0
    train_losses, val_losses = [], []
    train_accuracies, val_accuracies = [], []

for epoch in range(start_epoch, EPOCHS):
    model.train()
    train_loss = 0.0
    correct = 0
    total = 0
    iteration = 0

# Training loop with a progress bar
    train_pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS} Training", leave=False)
    for images, labels in train_pbar:
        iteration += 1
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)

        loss.backward()
        optimizer.step()

        batch_size = images.size(0)
        train_loss += loss.item() * batch_size

        # 멀티 라벨 정확도 계산
        # 1. 모델 출력에 Sigmoid 적용하여 확률 값으로 변환
        probabilities = torch.sigmoid(outputs)
        # 2. 임계값 (0.5) 기준으로 이진 예측
        predicted = (probabilities > 0.5).float()
        # 3. 예측 결과와 실제 라벨 비교하여 정확도 계산
        # 모든 라벨이 일치하는 경우만 정확하게 예측했다고 판단
        # all_equal = torch.all(predicted == labels, dim=1).sum().item() # 엄격한 정확도
        # 각 라벨별 정확도 평균을 계산하거나 다른 멀티 라벨 지표 사용
        correct_predictions = (predicted == labels).sum().item()
        total_elements = labels.numel() # 전체 라벨 요소의 개수

        # correct += all_equal # 엄격한 정확도 누적
        correct += correct_predictions # 전체 예측 중 맞는 예측의 개수
        total += total_elements # 전체 라벨 요소의 총 개수 (batch_size * num_classes)


        train_pbar.set_postfix({
            "Batch Loss": f"{loss.item():.4f}",
            "Avg Loss": f"{train_loss/total_elements:.4f}", # 손실은 전체 라벨 요소 개수로 평균
            "Acc": f"{correct/total:.4f}" # 정확도는 전체 라벨 요소 개수 대비 맞는 예측의 비율
        })

    epoch_train_loss = train_loss / (total / num_classes) if total > 0 else 0 # 배치 개수로 나누어 에포크 손실 계산
    train_losses.append(epoch_train_loss)
    train_acc = correct / total if total > 0 else 0 # 정확도 계산

    model.eval()
    val_loss = 0.0
    correct_val = 0
    total_val = 0
    val_pbar = tqdm(val_loader, desc=f"Epoch {epoch+1}/{EPOCHS} Validation", leave=False)
    with torch.no_grad():
        for images, labels in val_pbar:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)

            batch_size = images.size(0)
            val_loss += loss.item() * batch_size

            # 멀티 라벨 정확도 계산 (검증)
            # 1. 모델 출력에 Sigmoid 적용하여 확률 값으로 변환
            probabilities = torch.sigmoid(outputs)
            # 2. 임계값 (0.5) 기준으로 이진 예측
            predicted = (probabilities > 0.5).float()
            # 3. 예측 결과와 실제 라벨 비교하여 정확도 계산
            correct_predictions_val = (predicted == labels).sum().item()
            total_elements_val = labels.numel()

            correct_val += correct_predictions_val
            total_val += total_elements_val

            val_pbar.set_postfix({
                "Batch Loss": f"{loss.item():.4f}",
                "Avg Loss": f"{val_loss/total_elements_val:.4f}", # 손실은 전체 라벨 요소 개수로 평균
                "Acc": f"{correct_val/total_val:.4f}" # 정확도는 전체 라벨 요소 개수 대비 맞는 예측의 비율
            })

    epoch_val_loss = val_loss / (total_val / num_classes) if total_val > 0 else 0 # 배치 개수로 나누어 에포크 손실 계산
    val_losses.append(epoch_val_loss)
    val_acc = correct_val / total_val if total_val > 0 else 0 # 정확도 계산

    print(f"Epoch {epoch+1}/{EPOCHS} - Train Loss: {epoch_train_loss:.4f}, Train Acc: {train_acc:.4f} | "
          f"Val Loss: {epoch_val_loss:.4f}, Val Acc: {val_acc:.4f}")

    train_accuracies.append(train_acc)
    val_accuracies.append(val_acc)

    # Save checkpoint after every epoch
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'scheduler_state_dict': scheduler.state_dict(),
        'best_val_acc': best_val_acc,
        'epochs_no_improve': epochs_no_improve,
        'train_losses': train_losses,
        'val_losses': val_losses,
        'train_accuracies': train_accuracies,
        'val_accuracies': val_accuracies,
    }
    torch.save(checkpoint, checkpoint_file)
    # Also save a separate model file for each epoch if desired
    torch.save(model.state_dict(), f"model_epoch_{epoch+1}.pth")

    # Early stopping check
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        epochs_no_improve = 0
        torch.save(model.state_dict(), "best_Acne_swin_model.pth")  # Save best model separately
    else:
        epochs_no_improve += 1
        if epochs_no_improve >= PATIENCE:
            print("Early stopping triggered. Training stopped.")
            break

    scheduler.step()
    # print(met.metrics_report())

print("Training complete!")

import matplotlib.pyplot as plt

epochs_range = range(1, len(train_losses) + 1)

plt.figure(figsize=(10, 5))
plt.plot(epochs_range, train_losses, label='Train Loss')
plt.plot(epochs_range, val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 5))
plt.plot(epochs_range, train_accuracies, label='Train Accuracy')
plt.plot(epochs_range, val_accuracies, label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from tqdm import tqdm
from torchvision import transforms
from PIL import ImageFile
from sklearn.metrics import f1_score, multilabel_confusion_matrix
import numpy as np

# Assume that test_dataset and your model class SwinClassifier are already defined
BATCH_SIZE = 32
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

checkpoint_path = "best_Acne_swin_model.pth"
#checkpoint_path = "/content/drive/MyDrive/AI Project I/best_Acne_swin_model.pth"

model = SwinClassifier(num_classes=10)  # Create an instance of your model
# 파일에서 state_dict를 직접 로드합니다.
model.load_state_dict(torch.load(checkpoint_path))
model.to(device)
model.eval()

# Define the loss function (if you want to compute test loss)
criterion = nn.BCEWithLogitsLoss()

# Run testing/inference
correct = 0
total = 0
test_loss = 0.0
all_preds = []
all_labels = []

test_pbar = tqdm(test_loader, desc="Testing", leave=False)
with torch.no_grad():
    for images, labels in test_pbar:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        loss = criterion(outputs, labels.float())

        batch_size = images.size(0)
        test_loss += loss.item() * batch_size
        probabilities = torch.sigmoid(outputs)
        predicted = (probabilities > 0.5).float()
        correct += (predicted == labels).sum().item()
        total += predicted.numel()

        all_preds.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

        test_pbar.set_postfix({"Batch Loss": f"{loss.item():.4f}"})

avg_loss = test_loss / total if total > 0 else 0
accuracy = correct / total if total > 0 else 0

# Calculate F1 score and confusion matrix
f1 = f1_score(all_labels, all_preds, average='samples')  # or 'binary' for binary classification
conf_matrix_per_class = multilabel_confusion_matrix(all_labels, all_preds)
class_names = test_dataset.classes
print(f"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}")
print("Confusion Matrix per Class and Class Accuracy:")
for i, cm in enumerate(conf_matrix_per_class):
    tp = cm[1][1]  # True Positive
    fn = cm[1][0]  # False Negative
    fp = cm[0][1]  # False Positive
    tn = cm[0][0]  # True Negative

    # 정확도 계산: (TP + TN) / (TP + TN + FP + FN)
    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0

    # 클래스별 confusion matrix와 정확도 출력
    print(f"Class: {class_names[i]}")
    print(cm)
    print(f"Accuracy: {accuracy:.4f}")
    print()